{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market News Realtime Custom Notifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the project is to develop a POC application in order to assess the feasibility of developing a tool which notifies the user when a certain makert news comes up on the air.\n",
    "\n",
    "In order to do this a scraper will be built. Such scraper will be constantly querying the realtime news page of MarketWatch website, scraping the new entries added since the last run and checking for the trigger keywords that the user wants to keep a tab on, e.g. \"oil\", \"surge\", \"drops\". Additionally it would be good if the user could also select to notify him/her when the headline contains a percentage bigger than 5% for example, in conjunction with the previous words. This would allow to identify when a specific stock, commodity or currency drops or surges below or above a certain percentage.\n",
    "\n",
    "Also, as a last development, not included in the scope of this POC application, but which could be usefull for a real live application if the conclusions of this experiment turn out to be positive is to include a search engine which uses machine learning system, specifically semantic search. This would allow the user not only to select from a predetermined set of words like \"drop\", \"surge\", \"unstable\", etc. but to write in his/her own words what he or she wants to get notified for. And the semantic search would have the ability to retrieve headlines which agree in meaning with this search without the need to keep a huge dictionary synonym table.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** NOTES ON THE PAST **\n",
    "\n",
    "- First attempt to scrape some twitter feeds failed miserably since it was not nearly real-time and additionally it did not scraped all tweets, it seemed to randomly scrape some and miss some.\n",
    "- It was decided to use the Twitter stream API to check realtime capabilities as well as to increase the fidelity of information (that is, all tweets must be scraped). It worked. It is increadibly real-time. Seconds of difference perhaps.\n",
    "- The stream should follow users not keywords, the keyword part should be done on the server. This is so because the Twitter Stream API uses OR for the \"track\" and \"follow\" variables. So if one does track=\"oil,surge\" and follow=\"marketWatch\" it will get all tweets that have oil and surge keywords and also all tweets from marketWatch.\n",
    "\n",
    "** NOTES ON THE FUTURE **\n",
    "\n",
    "- Now we need to select a few users to stream from. Let's initially select major news outlets, major market players, and major market news outlets. The user should be able to follow anyone he or she would like though in conjunction with the keywords that he/she will be tracking.\n",
    "- Check the error that appears when a user enters a Twitter handle that does not exist. Catch it and show an error message.\n",
    "- When reaching the point at which we will be tracking keywords on the stream be aware that TextBlob may result usefull in correcting spelling errors, taking into account synonyms, pluralizations and perhaps even translations if there are any major local outlets in a language different to the one the user speaks. To check out the TextBlock documentation go here: http://textblob.readthedocs.io/en/dev/quickstart.html#get-word-and-noun-phrase-frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notifier Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to create desktop notification on OSX system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import module\n",
    "import os\n",
    "\n",
    "# The notifier function\n",
    "def notify(title, subtitle, message):\n",
    "    t = '-title {!r}'.format(title)\n",
    "    s = '-subtitle {!r}'.format(subtitle)\n",
    "    m = '-message {!r}'.format(message)\n",
    "    os.system('terminal-notifier {}'.format(' '.join([m, t, s])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creates the database table to store the information of news headlines that have been relevant to the user.\n",
    "2. Creates the database table to store the news obtained by the last run of the scraper so the monitor can process them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import module\n",
    "import sqlite3\n",
    "\n",
    "# This function creates a database instance which consists of 2 tables.\n",
    "# First table is user_headlines which consists of headlines that have matched the user match criteria\n",
    "# Second table are the realtime_headlines which consists of headlines that are yet to be matched angainst the user criteria\n",
    "def create_database():\n",
    "    print(\"started creating database...\")\n",
    "    # Connect to \"teeview_analytics\" database\n",
    "    conn = sqlite3.connect('market_news_watcher.db')\n",
    "    # Create \"campaigns\" table if it does not exist\n",
    "    user_headlines_table = conn.execute(\"SELECT headline FROM sqlite_master WHERE type='table' AND name='user_headlines'\").fetchall()\n",
    "    if len(user_headlines_table) == 0: conn.execute(\"create table user_headlines(headline)\")\n",
    "    # Create \"sales_data\" table if it does not exist\n",
    "    realtime_headlines_table = conn.execute(\"SELECT headline FROM sqlite_master WHERE type='table' AND name='realtime_headlines'\").fetchall()\n",
    "    if len(realtime_headlines_table) == 0: conn.execute(\"create table realtime_headlines(headline)\")\n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    print(\"finished creating database!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import module\n",
    "import tweepy\n",
    "\n",
    "# This should be stored as enviroment variables\n",
    "consumer_key = '1m06oM795BE0EuynpeLWbRNCO'\n",
    "consumer_secret = 'WMnnyzPQwLmDowvTjLGLperW0XmJVyaeOoWQXmLwjAjyyB40yW'\n",
    "access_token = '805435652707876864-ybtcv2DHVl740HYcMHjElAHnCQOsX2l'\n",
    "access_token_secret = 'S9zNQUkXlrGGnYoxTgt0bcXpJQXxyv9eroiKPgONLXKU7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authenticate application\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Override tweepy.StreamListener to add logic to on_status\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "\n",
    "# Create stream listener\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will be the list of news outlets, major market players and specialized market news twitter feeds the Stream will be following on.\n",
    "\n",
    "1. Currency rates:\n",
    "    - @ForexLive: https://twitter.com/ForexLive\n",
    "    - @currencynews: https://twitter.com/currencynews\n",
    "    - @FXstreetNews: https://twitter.com/fxstreetnews\n",
    "2. Market news:\n",
    "    - @MarketCurrents: https://twitter.com/marketcurrents (SeekingAlpha for Breaking News)\n",
    "    - @WSJmarkets: https://twitter.com/wsjmarkets\n",
    "    - @markets: https://twitter.com/markets (Bloomberg)\n",
    "    - @MarketWatch: https://twitter.com/MarketWatch\n",
    "    - @Reuters: https://twitter.com/Reuters\n",
    "    - @YahooFinance: https://twitter.com/YahooFinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_ids = {\n",
    "    \"MarketCurrents\": \"15296897\",\n",
    "    \"WSJmarkets\": \"28164923\",\n",
    "    \"markets\" : \"69620713\",\n",
    "    \"MarketWatch\" : \"624413\",\n",
    "    \"Reuters\" : \"1652541\",\n",
    "    \"YahooFinance\" : \"19546277\",\n",
    "    \"ForexLive\" : \"19399038\",\n",
    "    \"currencynews\" : \"24349486\",\n",
    "    \"FXstreetNews\" : \"27652717\"\n",
    "}\n",
    "# Start steam (sync)\n",
    "myStream.filter(follow=['15296897'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matcher Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Matches the newly scraped market news against the new headlines and notifies the user if it must. \n",
    "2. Stores the headlines of the notified news, that is, the news that matched the user search parameters.\n",
    "3. Removes from the database 2. the news that have already been checked against the user search parameters."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
